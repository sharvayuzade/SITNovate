{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>total_gyro</th>\n",
       "      <th>roll_avg_acc_X</th>\n",
       "      <th>roll_avg_acc_Y</th>\n",
       "      <th>roll_avg_acc_Z</th>\n",
       "      <th>roll_avg_gyro_X</th>\n",
       "      <th>roll_avg_gyro_Y</th>\n",
       "      <th>roll_avg_gyro_Z</th>\n",
       "      <th>tlt_X</th>\n",
       "      <th>tlt_Y</th>\n",
       "      <th>Still_Time</th>\n",
       "      <th>fall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.79</td>\n",
       "      <td>4.18</td>\n",
       "      <td>8.86</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>4.69</td>\n",
       "      <td>8.35</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.24</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>55254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.96</td>\n",
       "      <td>5.28</td>\n",
       "      <td>8.23</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>4.58</td>\n",
       "      <td>8.45</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>32.69</td>\n",
       "      <td>-13.37</td>\n",
       "      <td>55458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>6.59</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.33</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>4.72</td>\n",
       "      <td>8.40</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>-12.36</td>\n",
       "      <td>55662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>9.14</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.61</td>\n",
       "      <td>8.04</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.13</td>\n",
       "      <td>19.70</td>\n",
       "      <td>-80.04</td>\n",
       "      <td>55866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.12</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.48</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-69.66</td>\n",
       "      <td>-86.72</td>\n",
       "      <td>56070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-78.91</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>1642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>0.69</td>\n",
       "      <td>-8.46</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-65.18</td>\n",
       "      <td>10.06</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>1.54</td>\n",
       "      <td>-8.20</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-5.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-64.72</td>\n",
       "      <td>21.64</td>\n",
       "      <td>2050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>4.67</td>\n",
       "      <td>-9.49</td>\n",
       "      <td>6.44</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>12.38</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>1.78</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-55.87</td>\n",
       "      <td>35.97</td>\n",
       "      <td>2254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>0.13</td>\n",
       "      <td>-8.11</td>\n",
       "      <td>4.85</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.57</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-59.12</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1427 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x  acc_y  acc_z  gyro_x  gyro_y  gyro_z  total_acc  total_gyro  \\\n",
       "0     -0.79   4.18   8.86   -0.30    0.06    0.18       9.82        0.36   \n",
       "1     -1.96   5.28   8.23   -0.34   -0.17   -0.02       9.97        0.39   \n",
       "2     -1.44  -0.85   6.59   -0.92    1.60    0.33       6.80        1.88   \n",
       "3     -8.99   0.57   1.58   -0.32    4.30   -1.66       9.14        4.62   \n",
       "4    -13.12  -2.03   0.75   -1.28    0.23   -2.11      13.30        2.48   \n",
       "...     ...    ...    ...     ...     ...     ...        ...         ...   \n",
       "1422  -0.06  -9.79   1.92    0.53   -0.02    0.03       9.98        0.53   \n",
       "1423   0.69  -8.46   3.91   -0.53   -0.92   -0.81       9.35        1.34   \n",
       "1424   1.54  -8.20   3.87    0.72   -0.26   -0.33       9.20        0.83   \n",
       "1425   4.67  -9.49   6.44   -0.56   -0.12    0.22      12.38        0.61   \n",
       "1426   0.13  -8.11   4.85   -0.43    0.03    0.84       9.45        0.95   \n",
       "\n",
       "      roll_avg_acc_X  roll_avg_acc_Y  roll_avg_acc_Z  roll_avg_gyro_X  \\\n",
       "0              -1.39            4.69            8.35            -0.14   \n",
       "1              -1.27            4.58            8.45            -0.17   \n",
       "2              -1.41            4.72            8.40            -0.21   \n",
       "3              -1.41            3.61            8.04            -0.35   \n",
       "4              -2.93            3.00            6.75            -0.34   \n",
       "...              ...             ...             ...              ...   \n",
       "1422            0.76           -3.77            0.25            -1.05   \n",
       "1423            0.59           -4.98            0.59            -0.74   \n",
       "1424            0.61           -5.67            1.25            -0.70   \n",
       "1425            0.80           -6.18            1.78            -0.41   \n",
       "1426            1.57           -6.84            2.71            -0.44   \n",
       "\n",
       "      roll_avg_gyro_Y  roll_avg_gyro_Z  tlt_X  tlt_Y  Still_Time  fall  \n",
       "0                0.05             0.08  25.24  -5.10       55254     0  \n",
       "1                0.05             0.10  32.69 -13.37       55458     0  \n",
       "2                0.00             0.07  -7.33 -12.36       55662     0  \n",
       "3                0.32             0.13  19.70 -80.04       55866     0  \n",
       "4                1.12            -0.23 -69.66 -86.72       56070     0  \n",
       "...               ...              ...    ...    ...         ...   ...  \n",
       "1422             0.50            -0.13 -78.91  -1.86        1642     0  \n",
       "1423             0.39            -0.10 -65.18  10.06        1846     0  \n",
       "1424             0.13            -0.24 -64.72  21.64        2050     0  \n",
       "1425             0.05            -0.26 -55.87  35.97        2254     0  \n",
       "1426             0.02            -0.16 -59.12   1.53        2458     0  \n",
       "\n",
       "[1427 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('fall_merged.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Sitnovate\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9614 - loss: 0.3331 - val_accuracy: 0.9825 - val_loss: 0.0990\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0895 - val_accuracy: 0.9825 - val_loss: 0.0764\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0792 - val_accuracy: 0.9825 - val_loss: 0.0749\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0432 - val_accuracy: 0.9825 - val_loss: 0.0744\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0540 - val_accuracy: 0.9825 - val_loss: 0.0765\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0533 - val_accuracy: 0.9825 - val_loss: 0.0788\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0531 - val_accuracy: 0.9825 - val_loss: 0.0808\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0431 - val_accuracy: 0.9825 - val_loss: 0.0830\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0320 - val_accuracy: 0.9825 - val_loss: 0.0831\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0341 - val_accuracy: 0.9825 - val_loss: 0.0838\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0460 - val_accuracy: 0.9825 - val_loss: 0.0856\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0377 - val_accuracy: 0.9825 - val_loss: 0.0872\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0416 - val_accuracy: 0.9825 - val_loss: 0.0871\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0347 - val_accuracy: 0.9825 - val_loss: 0.0895\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0329 - val_accuracy: 0.9825 - val_loss: 0.0920\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0345 - val_accuracy: 0.9825 - val_loss: 0.0894\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0424 - val_accuracy: 0.9825 - val_loss: 0.0888\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0284 - val_accuracy: 0.9825 - val_loss: 0.0895\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0399 - val_accuracy: 0.9825 - val_loss: 0.0928\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0305 - val_accuracy: 0.9825 - val_loss: 0.0907\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0329 - val_accuracy: 0.9825 - val_loss: 0.0936\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0188 - val_accuracy: 0.9825 - val_loss: 0.0945\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0236 - val_accuracy: 0.9825 - val_loss: 0.0944\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0192 - val_accuracy: 0.9825 - val_loss: 0.0943\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0230 - val_accuracy: 0.9825 - val_loss: 0.0933\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0292 - val_accuracy: 0.9825 - val_loss: 0.0967\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0203 - val_accuracy: 0.9825 - val_loss: 0.0973\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0280 - val_accuracy: 0.9825 - val_loss: 0.0968\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0198 - val_accuracy: 0.9825 - val_loss: 0.0987\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0153 - val_accuracy: 0.9825 - val_loss: 0.0984\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0144 - val_accuracy: 0.9825 - val_loss: 0.0995\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0221 - val_accuracy: 0.9825 - val_loss: 0.0998\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0245 - val_accuracy: 0.9825 - val_loss: 0.0984\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0173 - val_accuracy: 0.9825 - val_loss: 0.1015\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0183 - val_accuracy: 0.9825 - val_loss: 0.1018\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0199 - val_accuracy: 0.9825 - val_loss: 0.1004\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0252 - val_accuracy: 0.9825 - val_loss: 0.1040\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.9825 - val_loss: 0.1028\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0212 - val_accuracy: 0.9825 - val_loss: 0.1057\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0192 - val_accuracy: 0.9825 - val_loss: 0.1047\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0292 - val_accuracy: 0.9825 - val_loss: 0.1098\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0145 - val_accuracy: 0.9825 - val_loss: 0.1056\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0274 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0142 - val_accuracy: 0.9825 - val_loss: 0.1093\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0172 - val_accuracy: 0.9825 - val_loss: 0.1125\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0222 - val_accuracy: 0.9825 - val_loss: 0.1124\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0185 - val_accuracy: 0.9825 - val_loss: 0.1157\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0193 - val_accuracy: 0.9825 - val_loss: 0.1159\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0227 - val_accuracy: 0.9825 - val_loss: 0.1168\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0142 - val_accuracy: 0.9825 - val_loss: 0.1198\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.1680 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Select features and target\n",
    "X = df.drop(columns=['fall']).values  # Features\n",
    "y = df['fall'].values  # Target (0 = No Fall, 1 = Fall)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Normalize data (important for NN models)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for ESP32\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Define Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Probability output\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"fall_detectionmodelshrpr.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000213389FB7F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000213389FB7F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
      "Fall Detected: 0 (Probability: 0.0760)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"fall_detectionmodelshrpr.h5\")\n",
    "\n",
    "# Load the saved scaler\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "def predict_fall(data):\n",
    "    \"\"\"\n",
    "    Predicts whether a fall has occurred based on input sensor data.\n",
    "    \n",
    "    :param data: List or array of sensor values\n",
    "    :return: Probability of fall (1 = Fall, 0 = No Fall)\n",
    "    \"\"\"\n",
    "    # Convert input data to numpy array and reshape for model\n",
    "    data = np.array(data).reshape(1, -1)\n",
    "    \n",
    "    # Normalize input data\n",
    "    data = scaler.transform(data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(data)\n",
    "    \n",
    "    # Convert probability to binary output\n",
    "    fall_detected = int(prediction[0][0] > 0.5)\n",
    "    \n",
    "    return fall_detected, prediction[0][0]\n",
    "\n",
    "# Example input\n",
    "sensor_data = [-9.86,-2.35,-4.84,1.0,0.58,-1.35,11.23,1.78,-9.08,-3.86,-4.03,-0.33,0.15,-0.24,-154.11,-116.14,4906]\n",
    "\n",
    "# Get prediction\n",
    "fall_status, probability = predict_fall(sensor_data)\n",
    "print(f\"Fall Detected: {fall_status} (Probability: {probability:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5199134 ,  0.26146518, -1.75537468,  0.0626217 , -1.22562409,\n",
       "        0.50326893,  1.02249666,  0.36955649, -2.04127084,  0.39529676,\n",
       "       -1.94988688,  0.08101083, -0.18303344,  1.04970237, -2.49604639,\n",
       "       -1.70370796, -0.70086953])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
